{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 아키텍처 one-hot-encoding\n",
    "\n",
    "# 입력층 노드를 입력 데이터 개수와 일치하도록 784개 설정\n",
    "# 은닉층 노드를 몇 개로 설정할 것인가는 정해진 규칙이 없으므로 100개 임의 설정 -> 최적의 개수 찾는 알고리즘 필요\n",
    "# 출력층 노드는 10개 설정? 0~9 중 하나의 숫자이므로 리스트에서 가장 큰 값을 가지는 인덱스를 정답으로 판단할 수 있도록 출력 노드 10개로 설정: one-hot-encoding\n",
    "\n",
    "# NeuralNetwork class\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "# MNIST_Test Class\n",
    "\n",
    "class MNIST_Test:\n",
    "    \n",
    "    # 생성자\n",
    "    # xdata, tdata => numpy.array(...)\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes # input_nodes = 784\n",
    "        self.hidden_nodes = hidden_nodes # hidden_nodes = 100\n",
    "        self.output_nodes = output_nodes # output_nodes = 10\n",
    "        \n",
    "        # 은닉층 가중치  W2  Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)      \n",
    "        \n",
    "        # 출력층 가중치는 W3  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)      \n",
    "        \n",
    "        # 2층 hidden layer unit \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        #self.W2 = np.random.rand(input_nodes, hidden_nodes)  \n",
    "        #self.b2 = np.random.rand(hidden_nodes)\n",
    "        \n",
    "        # 3층 output layer unit : 1 개 \n",
    "        #self.W3 = np.random.rand(hidden_nodes,output_nodes)\n",
    "        #self.b3 = np.random.rand(output_nodes)\n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        print(\"MNIST_Test object is created !!!\")\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # obtain W and b\n",
    "    def get_W_b(self):\n",
    "        \n",
    "        return self.W2,  self.b2, self.W3, self.b3\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):    \n",
    "        \n",
    "        z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "    \n",
    "        # MNIST 경우는 one-hot encoding 을 적용하기 때문에\n",
    "        # 0 또는 1 이 아닌 argmax() 를 통해 최대 인덱스를 넘겨주어야 함\n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, input_data, target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        # list which contains (index, label, prediction) value\n",
    "        index_label_prediction_list = []\n",
    "        \n",
    "        # temp list which contains label and prediction in sequence\n",
    "        temp_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "                        \n",
    "            label = int(target_data[index])\n",
    "                        \n",
    "            # normalize\n",
    "            data = (input_data[index, :] / 255.0 * 0.99) + 0.01\n",
    "      \n",
    "            predicted_num = self.predict(data)\n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                temp_list.append(index)\n",
    "                temp_list.append(label)\n",
    "                temp_list.append(predicted_num)\n",
    "                \n",
    "                index_label_prediction_list.append(temp_list)\n",
    "                \n",
    "                temp_list = []\n",
    "                \n",
    "        print(\"Current Accuracy = \", len(matched_list)/(len(input_data)) )\n",
    "        \n",
    "        return matched_list, not_matched_list, index_label_prediction_list\n",
    "    \n",
    "        \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self, input_data, target_data):\n",
    "        \n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "    \n",
    "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "        \n",
    "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "    \n",
    "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n",
      "MNIST_Test object is created !!!\n",
      "Neural Network Learning using Numerical Derivative...\n",
      "epochs =  0 , index =  0 , loss value =  9.009995183389151\n",
      "epochs =  0 , index =  200 , loss value =  3.249003671046065\n",
      "epochs =  0 , index =  400 , loss value =  2.749982169335703\n",
      "epochs =  0 , index =  600 , loss value =  2.966049241744029\n",
      "epochs =  0 , index =  800 , loss value =  2.72305867291746\n",
      "epochs =  0 , index =  1000 , loss value =  2.4351034833542746\n",
      "epochs =  0 , index =  1200 , loss value =  1.8818115398544002\n",
      "epochs =  0 , index =  1400 , loss value =  1.9371458437505575\n",
      "epochs =  0 , index =  1600 , loss value =  2.9574826897234288\n",
      "epochs =  0 , index =  1800 , loss value =  2.294415329091309\n",
      "epochs =  0 , index =  2000 , loss value =  3.3264463353587934\n",
      "epochs =  0 , index =  2200 , loss value =  2.204253946563692\n",
      "epochs =  0 , index =  2400 , loss value =  1.86612459361987\n",
      "epochs =  0 , index =  2600 , loss value =  2.546647224048486\n",
      "epochs =  0 , index =  2800 , loss value =  2.1402039241716606\n",
      "epochs =  0 , index =  3000 , loss value =  3.0499535819313635\n",
      "epochs =  0 , index =  3200 , loss value =  2.2049644137421796\n",
      "epochs =  0 , index =  3400 , loss value =  1.3657336096764947\n",
      "epochs =  0 , index =  3600 , loss value =  2.2152504920063136\n",
      "epochs =  0 , index =  3800 , loss value =  1.1385255048268514\n",
      "epochs =  0 , index =  4000 , loss value =  1.3502381737866755\n",
      "epochs =  0 , index =  4200 , loss value =  1.6429982750838201\n",
      "epochs =  0 , index =  4400 , loss value =  1.1471392806393454\n",
      "epochs =  0 , index =  4600 , loss value =  2.611273515253018\n",
      "epochs =  0 , index =  4800 , loss value =  2.1517998087199883\n",
      "epochs =  0 , index =  5000 , loss value =  1.103521528165524\n",
      "epochs =  0 , index =  5200 , loss value =  2.028108985349369\n",
      "epochs =  0 , index =  5400 , loss value =  2.0508562358574194\n",
      "epochs =  0 , index =  5600 , loss value =  1.5447138269489473\n",
      "epochs =  0 , index =  5800 , loss value =  2.9696397294576404\n",
      "epochs =  0 , index =  6000 , loss value =  0.7438978025822479\n",
      "epochs =  0 , index =  6200 , loss value =  2.2086798738694466\n",
      "epochs =  0 , index =  6400 , loss value =  0.7875946876575968\n",
      "epochs =  0 , index =  6600 , loss value =  2.098430755481211\n",
      "epochs =  0 , index =  6800 , loss value =  0.8699518045548221\n",
      "epochs =  0 , index =  7000 , loss value =  1.8965815170683584\n",
      "epochs =  0 , index =  7200 , loss value =  1.8407106229684325\n",
      "epochs =  0 , index =  7400 , loss value =  1.606542216744342\n",
      "epochs =  0 , index =  7600 , loss value =  1.4403596370635285\n",
      "epochs =  0 , index =  7800 , loss value =  1.2709433856806964\n",
      "epochs =  0 , index =  8000 , loss value =  0.6268332490312511\n",
      "epochs =  0 , index =  8200 , loss value =  5.2051066634334\n",
      "epochs =  0 , index =  8400 , loss value =  1.1900723634106516\n",
      "epochs =  0 , index =  8600 , loss value =  2.195464259424435\n",
      "epochs =  0 , index =  8800 , loss value =  0.8191996444952028\n",
      "epochs =  0 , index =  9000 , loss value =  1.2147036280666497\n",
      "epochs =  0 , index =  9200 , loss value =  0.7596370709275727\n",
      "epochs =  0 , index =  9400 , loss value =  0.851091936287177\n",
      "epochs =  0 , index =  9600 , loss value =  0.7164930007126707\n",
      "epochs =  0 , index =  9800 , loss value =  2.1219477098875466\n",
      "epochs =  0 , index =  10000 , loss value =  0.6474403769937016\n",
      "epochs =  0 , index =  10200 , loss value =  1.1288711596051735\n",
      "epochs =  0 , index =  10400 , loss value =  1.4760797580501597\n",
      "epochs =  0 , index =  10600 , loss value =  0.9089757330356886\n",
      "epochs =  0 , index =  10800 , loss value =  2.774042684845216\n",
      "epochs =  0 , index =  11000 , loss value =  0.6687572314951664\n",
      "epochs =  0 , index =  11200 , loss value =  0.6840909971744796\n",
      "epochs =  0 , index =  11400 , loss value =  0.7609672922293512\n",
      "epochs =  0 , index =  11600 , loss value =  4.576108589905207\n",
      "epochs =  0 , index =  11800 , loss value =  0.6540086033158276\n",
      "epochs =  0 , index =  12000 , loss value =  0.9709136026054038\n",
      "epochs =  0 , index =  12200 , loss value =  1.0415005183780375\n",
      "epochs =  0 , index =  12400 , loss value =  0.6759407088132219\n",
      "epochs =  0 , index =  12600 , loss value =  2.1000846392077372\n",
      "epochs =  0 , index =  12800 , loss value =  1.4779723192542729\n",
      "epochs =  0 , index =  13000 , loss value =  0.961572843390066\n",
      "epochs =  0 , index =  13200 , loss value =  1.6093856962713566\n",
      "epochs =  0 , index =  13400 , loss value =  1.1223637023916493\n",
      "epochs =  0 , index =  13600 , loss value =  0.6438983014917129\n",
      "epochs =  0 , index =  13800 , loss value =  1.1183138705907796\n",
      "epochs =  0 , index =  14000 , loss value =  0.6242976805519223\n",
      "epochs =  0 , index =  14200 , loss value =  0.826790881340853\n",
      "epochs =  0 , index =  14400 , loss value =  0.6874923313567413\n",
      "epochs =  0 , index =  14600 , loss value =  0.7604344533790558\n",
      "epochs =  0 , index =  14800 , loss value =  0.9237845904087175\n",
      "epochs =  0 , index =  15000 , loss value =  1.1468559139967933\n",
      "epochs =  0 , index =  15200 , loss value =  0.6031035876222224\n",
      "epochs =  0 , index =  15400 , loss value =  0.9023635252030561\n",
      "epochs =  0 , index =  15600 , loss value =  0.7011855577640175\n",
      "epochs =  0 , index =  15800 , loss value =  1.0717327726140737\n",
      "epochs =  0 , index =  16000 , loss value =  0.6130460340955307\n",
      "epochs =  0 , index =  16200 , loss value =  2.0830809022768064\n",
      "epochs =  0 , index =  16400 , loss value =  1.445712120597012\n",
      "epochs =  0 , index =  16600 , loss value =  1.8781682083203866\n",
      "epochs =  0 , index =  16800 , loss value =  0.6012609396955277\n",
      "epochs =  0 , index =  17000 , loss value =  0.9451653369483497\n",
      "epochs =  0 , index =  17200 , loss value =  1.1474675730521484\n",
      "epochs =  0 , index =  17400 , loss value =  2.4367224002052774\n",
      "epochs =  0 , index =  17600 , loss value =  0.9830370555927526\n",
      "epochs =  0 , index =  17800 , loss value =  0.83500797443433\n",
      "epochs =  0 , index =  18000 , loss value =  1.3026329228324354\n",
      "epochs =  0 , index =  18200 , loss value =  1.048646461251679\n",
      "epochs =  0 , index =  18400 , loss value =  0.7107095523639071\n",
      "epochs =  0 , index =  18600 , loss value =  0.9436162061019386\n",
      "epochs =  0 , index =  18800 , loss value =  0.5912673781233917\n",
      "epochs =  0 , index =  19000 , loss value =  0.8113352325381092\n",
      "epochs =  0 , index =  19200 , loss value =  0.7551271002841972\n",
      "epochs =  0 , index =  19400 , loss value =  0.673675422798433\n",
      "epochs =  0 , index =  19600 , loss value =  1.1956496677027812\n",
      "epochs =  0 , index =  19800 , loss value =  0.6740751587295866\n",
      "epochs =  0 , index =  20000 , loss value =  0.6949887576012783\n",
      "epochs =  0 , index =  20200 , loss value =  0.7436440608525412\n",
      "epochs =  0 , index =  20400 , loss value =  0.6226453213147454\n",
      "epochs =  0 , index =  20600 , loss value =  1.6436060606481275\n",
      "epochs =  0 , index =  20800 , loss value =  0.7027985619566073\n",
      "epochs =  0 , index =  21000 , loss value =  1.7057077933956748\n",
      "epochs =  0 , index =  21200 , loss value =  0.5917841650507657\n",
      "epochs =  0 , index =  21400 , loss value =  0.650337377802193\n",
      "epochs =  0 , index =  21600 , loss value =  0.6277144399605425\n",
      "epochs =  0 , index =  21800 , loss value =  0.6557141407437317\n",
      "epochs =  0 , index =  22000 , loss value =  1.1283607469410353\n",
      "epochs =  0 , index =  22200 , loss value =  4.302098898751232\n",
      "epochs =  0 , index =  22400 , loss value =  1.5907382749994616\n",
      "epochs =  0 , index =  22600 , loss value =  0.6455713499556529\n",
      "epochs =  0 , index =  22800 , loss value =  1.940732171688158\n",
      "epochs =  0 , index =  23000 , loss value =  0.6091487654386637\n",
      "epochs =  0 , index =  23200 , loss value =  2.023245625844662\n",
      "epochs =  0 , index =  23400 , loss value =  2.041163568956854\n",
      "epochs =  0 , index =  23600 , loss value =  0.6541644710557233\n",
      "epochs =  0 , index =  23800 , loss value =  0.7067183552581411\n",
      "epochs =  0 , index =  24000 , loss value =  0.6731006998234411\n",
      "epochs =  0 , index =  24200 , loss value =  0.5893207533155262\n",
      "epochs =  0 , index =  24400 , loss value =  0.6784903376389707\n",
      "epochs =  0 , index =  24600 , loss value =  0.7298773790754643\n",
      "epochs =  0 , index =  24800 , loss value =  0.6589143788952234\n",
      "epochs =  0 , index =  25000 , loss value =  1.8154498182045329\n",
      "epochs =  0 , index =  25200 , loss value =  1.6716385251746484\n",
      "epochs =  0 , index =  25400 , loss value =  0.9612313380963036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , index =  25600 , loss value =  0.6322687686108354\n",
      "epochs =  0 , index =  25800 , loss value =  7.1327537595878905\n",
      "epochs =  0 , index =  26000 , loss value =  0.733614438324033\n",
      "epochs =  0 , index =  26200 , loss value =  0.6164882832995988\n",
      "epochs =  0 , index =  26400 , loss value =  0.8528805535175816\n",
      "epochs =  0 , index =  26600 , loss value =  3.095247390781475\n",
      "epochs =  0 , index =  26800 , loss value =  0.6047352314272652\n",
      "epochs =  0 , index =  27000 , loss value =  1.5169627154376746\n",
      "epochs =  0 , index =  27200 , loss value =  0.7259315747119668\n",
      "epochs =  0 , index =  27400 , loss value =  0.7084504187704805\n",
      "epochs =  0 , index =  27600 , loss value =  0.5828402899534997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fad5347658f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mtarget_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e04c6e7876fd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_data, target_data)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e04c6e7876fd>\u001b[0m in \u001b[0;36mnumerical_derivative\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdelta_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mfx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# f(x-delta_x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfx1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfx2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdelta_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e04c6e7876fd>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e04c6e7876fd>\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-7\u001b[0m    \u001b[1;31m# log 무한대 발산 방지\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training data \n",
    "training_data = np.loadtxt(r'C:\\Users\\allma\\Desktop/mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape)\n",
    "\n",
    "#hyper-parameter\n",
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 30  # hidden nodes 개수. Test 8->30\n",
    "o_nodes = 10    # output nodes 개수\n",
    "lr = 1e-2      # learning rate\n",
    "epochs = 1   # 반복횟수\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성\n",
    "loss_val_list = []\n",
    "\n",
    "# MNIST_Test 객체 생성\n",
    "obj = MNIST_Test(i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Numerical Derivative...\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epochs):\n",
    "    \n",
    "    for index in range(len(training_data)):    \n",
    "                \n",
    "        # input_data, target_data normalize : 입력데이터는 0~255 이기 때문에 가끔 overflow 발생, 따라서 모든 입력값을 0~1 값으로 normalize\n",
    "        input_data = ((training_data[index, 1:] / 255.0) * 0.99) + 0.01\n",
    "        \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(training_data[index, 0])] = 0.99\n",
    "        \n",
    "        obj.train(input_data, target_data)\n",
    "        \n",
    "        if (index % 200 == 0):\n",
    "            print(\"epochs = \", step, \", index = \", index, \", loss value = \", obj.loss_val())\n",
    "            \n",
    "        # 손실함수 값 저장\n",
    "        loss_val_list.append(obj.loss_val())        \n",
    "\n",
    "end_time = datetime.now()\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "Current Accuracy =  0.9122\n"
     ]
    }
   ],
   "source": [
    "test_data = np.loadtxt(r'C:\\Users\\allma\\Desktop/mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "\n",
    "test_input_data = test_data[ :, 1: ]\n",
    "test_target_data = test_data[ :, 0 ]\n",
    "\n",
    "(true_list_1, false_list_1, index_label_prediction_list) = obj.accuracy(test_input_data, test_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실함수 추세 확인\n",
    "x_data_list = [ index for index in range(len(training_data)) ]\n",
    "Y_DATA_LIST = []\n",
    "\n",
    "for index in range(0, len(loss_val_list), 500):\n",
    "    Y_DATA_LIST.append(loss_val_list[index])\n",
    "    \n",
    "plt.title('MNIST Loss Value Trend')\n",
    "plt.xlabel('data index ( X 500)')\n",
    "plt.ylabel('loss value')\n",
    "plt.grid()\n",
    "#plt.ylim(2.1, 7.1)\n",
    "#plt.plot(x_data_list, loss_val_list, color='b')\n",
    "plt.plot(Y_DATA_LIST, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
